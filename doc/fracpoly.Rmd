---
title: "Fractional Polynomial NMA Example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"Fractional Polynomial NMA Example"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo=TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

```{r setup, results="hide", message=FALSE, warning=FALSE}
library(BristolTAG)
library(tidyverse)
library(R2jags)
library(mcmcplots)
library(doBy)
library(survival)
library(RColorBrewer)
```

This vignette illustrates how to use the various functions created to run fractional polynomial analysis of survival data for the NICE NSCLC pathways project. Note that, unlike Freeman’s models, I’ve written these in JAGS because it is easier to run directly from R, which makes our workflow much easier. This does mean that JAGS needs to be installed separately. It can be downloaded from here: https://sourceforge.net/projects/mcmc-jags/files/latest/download

Since these functions can be run rapidly within a script, we’ll avoid writing CSV files to the drive, since that has the danger of creating a messy file structure. However, I will save the resulting JAGS models, since these take time to run so we don’t want to have to rerun them every time we want to examine outputs.

This example uses 1st order fractional polynomials, but it should be pretty obvious how to extend it to 2nd order. I’ll include an example of how to call the JAGS script for the 2nd order model too though.


## Preparing the data

To run the analyses we need to have IPD KM data. This can be digitized using the Guyott method, and other merging, subsetting should also be done prior to this (e.g. need to merge reported PDL-1 categories). There are other functions for this, but I won’t include them in this vignette as that’s a separate workflow (see `vignette("Extraction", "BristolTAG")`). For this we’ll assume that we have IPD KM data that is in the format ready for analysis.


### Checking for proportional hazards

Proportional hazards can be assessed using log-log plots. We can plot these for multiple studies simultaneously using `loglog_plot()`. This takes a data frame of IPD (can be digitized) with one row per patient and the following variables:

* `time` A numeric vector of times at which event/censoring occured
* `event` A binary vector indicating whether an event (`1`) or censoring (`0`) occured
* `treatment` A factor variable for treatment name
* `study` A factor variable for study name

We can then plot the curves, done below using PFS data for the NS1 node. 

```{r}
# Load the data to use
#df <- read.csv("Analysis/NS1/fracpoly/NS1 PFS IPD.csv")
df <- NS1_PFS # (example here loads it from package to allow vignette to run)

loglog_plot(df)
```

The output is a `ggpolot` object so you can edit labels, axes, etc. This is the same for all the plots generated in the `BristolTAG` package.


### Aggregating the data

To run fractional polynomial models on the log-hazard function (the model developed by Jansen), the first step is to aggregate the IPD into specified time intervals using `anova_data()`. We’ll use intervals of 1 week for this example (specified in `timepoints`), but we can look at changing that if we need to.

The IPD must be in the same format as described above for creating loglog plots. I’ll show this using the same PFS data for the NS1 node.

Treatments are named within the code below, but they can be reordered later in the fractional polynomial data prep function.

```{r}
# Apply function
anova <- anova_data(timepoints=seq(0,72, by=1), 
                      df=df)
```


### Preparing the data for JAGS

Next step is to get the data in the format we need for JAGS. This includes adding study and arm indices, and getting the data into a list.

Within `fp_data()` the treatment names should be specified **within the order you want them to be indexed in the network**. If they don’t match the treatment names specified within the IPD data then an error will be thrown.

```{r}
jagsdat <- fp_data(anova, trtnames=c("BCP", "ABCP", "PPCT", "PCT"))
```


## Running the model

### Defining initial values

Initial values can be specified manually by defining a list (of length 3 for 3 chains, and each element is a named list of parameters), or they can be automated using the `fp_geninits()` function. This uses fixed values for 2 chains and then uses random (but reasonable) values for the 3rd. The number of studies (`ns`) and the fractional polynomial order need to be specified, and the `seed` is optional for reproducibility.

```{r}
inits <- fp_geninits(ns=4, polyorder=1, seed=890421)
```


### Running a sequence of models

Because there are multiple fractional polynomial models that can be run with different powers (particularly for 2nd order models of which there are n(P)2), there's a function for running them all sequentially and saving them to an object/file so that you can set it off running and go and do something fun like play badminton or go to the pub.

`sequence_fpoly()` takes similar commands to the more verbose `jags()` function (see sections below), but doesn't require specification of the model code since it always uses the basic 1st or 2nd order fractional polynomial. As with `jags()` you can specify the number of iterations, initial values, etc. - for more details see `?R2jags::jags`. 

You only have to pass it the correct dataset and to specify the fractional polynomial `powers` that you want to explore, as well as the `polyorder` of the fractional polynomial.

```{r, results="hide"}
modseq <- sequence_fpoly(jagsdat, powers=c(-1,-0.5), polyorder=1, inits=inits)
```

You can also specify a `savefile` (format must be `.rds`) where the resulting set of models should be saved (it saves after each model is run in case something crashes part way through), and set `overwrite==TRUE` if you want the previous `.rds` file to be overwritten (setting it to `FALSE` means that new models will be appended to the existing file). 

The resulting object is a named list of models (so it could be dangerously massive if exploring several 2nd order FP powers). Note that this function does not check for convergence - that's something you have to do yourself (I might write another function for that but that would only rely on checking Rhat values anyway, which isn't perfect). 

If there are errors in running a model (I think for some positive 1st order powers the default initial values might be wrong) then the list element will be the corresponding error message rather than the model results.


### Calling JAGS (for writing slightly more flexible models)

The more verbose way to run a single model (this will allow us to run edited scripts if we want to fit more complex models) is to use `R2jags::jags()`. If we're doing this then the first thing here is to note that we need to additionally specify the fractional polynomial power value that we want to use. So the first bit of our code below adds that as data to the `jagsdat` object.

JAGS is then called to run the actual model. There are various arguments within this which you can check in the help file (`?jags`), but most of them should be pretty self explanatory. Another function (`jags.parallel()`) allows JAGS to be run in parallel, which might be useful for really slow models. I’ve also set a seed to get reproducible results (though these will be different if different initial values are used).

The main thing that we might want to change is the choice of model, specified within the `model.file` argument. My plan is that we save all models in a folder (`"Analysis/JAGSmodels"`) as separate `.jags` files, and we then reference the location to them with the `model.file` argument depending on which model we want to run. However, standard ones will be saved within the `BristolTAG` package, and the code below (as well as the `sequence_fpoly()` function) will read one of these. The current code is for a 1st order fractional polynomial, but we can write other code for 2nd order, other distributions, random effects models, class models, etc. as needed.

I’ve specified that we should monitor the `d` (needed for time-varying HRs and predictions), the `mu` (needed for predictions), and the `dev` and `totresdev` (needed to look at model fit). DIC is also automatically monitored within the model.

In order to allow the other functions in the package to run on the resulting JAGS object, we also have to set some attributes (treatment and study names).

```{r, results="hide"}
# Set fractional polynomial power
jagsdat$P1 <- -0.5

# Model does not include (or monitor) rankings - can easily be done in R
jagsmod <- jags(data=jagsdat, inits=inits,
                parameters.to.save=c("d", "mu", "dev", "totresdev"),
                model.file=system.file("JAGSmodels", "FE_1st_order_model.jags", package="BristolTAG"),
                jags.seed=890421,
                n.iter=15000, n.burnin=2000, n.thin=1
)

# Set attributes to match those of jagsdat
attr(jagsmod, "trtnames") <- attr(jagsdat, "trtnames")
attr(jagsmod, "studynames") <- attr(jagsdat, "studynames")
attr(jagsmod, "ipd") <- attr(jagsdat, "ipd")
```

It’s a good idea to save the model afterwards as an RDS file that can be loaded into R. If you use the following command it will save the file with a name that indicates the fractional polynomial power value used.

```{r, eval=FALSE}
# Note that eval=FALSE so this command won't overwrite files document is rendered
saveRDS(jagsmod, file=paste0("Analysis/NS1/JAGS_Results/pfs_fpoly1_", jagsdat$P1))
```


## Inspecting results

### Table of model fit stats for comparing models

You can easily compare models and check summary statistics for convergence by calling the `summary()` function on an object created by `sequence_fpoly()` (or by using `summary.sequence.fpoly()`). This outputs a tibble (data frame) of model fit statistics and an indicator of convergence based on an Rhat threshold (which you can specify in the function). Note that this is not a fail-safe test for convergence, but is a good rule of thumb. The default cutoff is 1.05.

```{r}
summary(modseq)
```


### Model diagnostics

It is probably also good to check convergence in more detail for final models, to ensure the treatment effect parameters have converged. 

There are various packages to assess model convergence. The coda one allows lots of detailed investigation of this. But it typically requires running lots of different arguments. I like the `mcmcplots` package because you can run a single command and it outputs an HTML of various diagnostics. The `parms` argument takes the names of monitored nodes that you want to look at diagnostics for. I’m mainly looking at `d`, since if this converges then other parameters are also likely to have done so.

```{r, eval=FALSE}
mcmcplot(jagsmod, parms = c("d"))
```


### Residual deviance

Model fit can be assessed using residual deviance. This can be plotted for a single model, or two models can be compared (dev-dev plots) using `devplot()`. **Note that for these to work, `dev` and `totresdev` must have been monitored in the model.**

All observations are plotted in order, so it’s quite hard to work out which points correspond to which study/arm. `vline` can be set to either `"study"` or `"arm"` to plot vertical lines that indicate the separation of studies/arms. Study/arm 1 will be nearest to the origin.

```{r}
# Looking at model fit of a single model
devplot(jagsmod)
```

```{r}
# Dev-dev plot for comparing models
# We'll compare the two models run previously using sequence_fpoly()
devplot(jagsmod1=modseq$`FP_-1`, jagsmod2=modseq$`FP_-0.5`)
```

### Predicted quantities

#### Time-varying hazard ratios

Time-varying HRs (or log-HRs) can be calculated using `hrcalc()`. This takes the JAGS object, and you need to specify times, a vector of time-points at which to calculate HRs. `eform=TRUE` specifies that you want to exponentiate the calculated log-HRs and return HRs. It might take a bit of run as it performs the calculation on all MCMC samples.

```{r}
hazardrats <- hrcalc(jagsmod, times=seq(1,60, length.out=100), eform=TRUE)
```

The returned object is a list which contains a data frame of posterior summary statistics for all the HRs (every treatment vs every other treatment) at every time-point up to maxt, as well as a full array of all the MCMC samples for the HRs.

These can be plotted by calling plot() on an object of class `"hazard.ratios"` generated by `hrcalc()` (or by using `plot.hazard.ratios()`). `reftrt` must be used to specify which treatment should be the reference treatment, and all time-varying HRs will be plotted versus this treatment.

```{r}
plot(hazardrats, reftrt = "BCP")
```


#### Survival predictions

Predictions at specific survival times can be calculated using a specific study baseline. This can be done by passing the JAGS model to `survcalc()`. Within this function, the `times` at which to estimate survival quantities should be specified (for plotting it's best to choose an even sequence of numbers).

The important thing to consider here is which study should be used as baseline. `refstudy` takes the name of the study (it must be named the same as in the original dataset on which the model was run) to use as the reference for predictions. **Generated survival quantities will therefore be specific to the population in this study**.

Note that these calculations can take some time to run (depending on the number of MCMC samples in the model and the number of time-points at which survival quantities should be predicted). To speed up the computation a smaller number for `n.mcmc` can be used. This defines the number of MCMC samples that should be drawn at random for calculations. If left as `NULL` then all the samples will be used. Note that a smaller number will lead to more MCMC error.

```{r, results="hide"}
# Generate survival quantities
surv <- survcalc(jagsmod, refstudy="KEYNOTE-189")
```

The resulting object contains the following quantities at each time point and for each treatment, both as arrays of MCMC values and as data frames of posterior summary statistics:

* `"haz"` hazards
* `"cumhaz"` cumulative hazards
* `"mort"` mortality probability
* `"S"` survival probabilities (note that S is upper case)

You can easily view posterior summaries:

```{r}
head(surv$summary$S)
```

But a much easier way of understanding the data is to plot these summaries. This can be done using `plot()` (or `plot.surv.predicts()`) on an object of class `"surv.predicts"` generated by `survcalc()`.

Within the function you can define the survival quantity to be plotted (`"haz"`, `"cumhaz"`, `"mort"`, `"S"`), the treatments to be plotted (`treats`), and whether the 95% credible intervals should be plotted (`plotinterval=TRUE`)

```{r}
plot(surv, quantity="S", treats=c("ABCP", "PPCT"))
```

It's also possibly to easily calculate the Area Under the Curve (AUC) for any of the predicted quantities using `auc()`. You need to specify a time interval (`tint`) within which AUC should be calculated, and also which quantity you want to calculate AUC for (default is `"S"`).

```{r}
auc.surv <- auc(surv, quantity="S", tint=c(1,50))
print(auc.surv)
```


#### Plotting survival predictions with raw Kaplan-Meier data

To add KM data we simply specify the argument `overlay.km=TRUE` in `plot.surv.predicts()`. By default this will use the IPD for the reference study used for the predictions (as this is the only KM data that it makes sense to compare predictions to). In this case it is for the KEYNOTE-189 study.

As you can see, the model below (1st order fractional polynomial with power of -0.5) fits the KEYNOTE-189 data very poorly.

```{r, warning=FALSE}
plot(surv, treats=c("PCT", "PPCT"), overlay.km = TRUE)
```

